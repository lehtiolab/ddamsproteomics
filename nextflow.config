import groovy.json.JsonSlurper

plugins {
  id 'nf-schema@2.2.0'
}

// Dont warn on withName in config without a process in running pipeline
nextflow.enable.configProcessNamesValidation = false

// Global default params, used in configs
params {
  help = false
  outdir = './results'
  tracedir = "${params.outdir}/pipeline_info"
  clusterOptions = false
  external_config_version = 'master'

  name = false
  input = null
  tdb = false
  mods = false
  sage = false
  msgf = false
  locptms = false
  ptms = false
  totalproteomepsms = false
  // 50 is the minimum score for "good PTM" in HCD acc. to luciphor2 paper
  // TODO evaluate if we need to set it higher
  ptm_minscore_high = 50
  phospho = false
  maxvarmods = 2
  isobaric = false
  remove_channels = false
  instrument = 'qe' // Default instrument is Q-Exactive
  prectol = '10.0ppm'
  iso_err = '-1,2'
  frag = 'auto'
  enzyme = 'trypsin'
  plate = null
  fraction = null
  terminicleaved = 'full' // semi, non
  maxmiscleav = -1 // Default MSGF is no limit
  minpeplen = 7
  maxpeplen = 50
  mincharge = 2
  maxcharge = 6
  psmconflvl = 0.01
  pepconflvl = 0.01
  proteinconflvl = 0.01
  activation = 'auto' // Only for isobaric quantification
  mediannormalize = false
  minprecursorpurity = 0
  ms1qmztol = 5 // in ppm
  ms1qrttol = 18 // in seconds
  genes = false
  ensg = false
  fastadelim = false
  genefield = false
  quantlookup = false
  hirief = false
  onlypeptides = false
  noquant = false
  noms1quant = false
  hardklor = false
  keepnapsmsquant = false
  report_seqmatch = false
  sampletable = false
  deqms = false
  targetpsmlookup = false
  decoypsmlookup = false
  targetpsms = false
  decoypsms = false
  ptmpsms = false
  oldmzmldef = false

  strips = ['3-10': [intercept: 3.5478, fr_width: 0.0676, tolerance: 0.11, fr_amount: 72, reverse: false],
            '3.7-4.9': [intercept: 3.5959, fr_width: 0.0174, tolerance: 0.08, fr_amount: 72, reverse: false],
            '11-6': [intercept: 10.3936, fr_width: -0.0762, tolerance: 0.11, fr_amount: 60, reverse: true],
            '6-9': [intercept: 6.1159, fr_width: 0.0336, pi_tolerance: 0.11, fr_amount: 72, reverse: false],
            '3.4-4.8': ['1-21': [intercept: 3.4395, fr_width: 0.0221, tolerance: 0.08, fr_amount: 21, reverse: false],
                        '22-64': [intercept: 3.6374, fr_width: 0.0128, tolerance: 0.08, fr_amount: 43, reverse: false],
                        '65-72': [intercept: 1.7364, fr_width: 0.0424, tolerance: 0.08, fr_amount: 8, reverse: false],
             ],

  ]
  minpsms_luciphor = 50
  msgfmods = "$baseDir/assets/msgfmods.txt"
}


def jsonslurp = new JsonSlurper()
def containers = jsonslurp.parseText(new File("${baseDir}/containers.json").text)
params.__containers = containers


includeConfig 'conf/base.config'
profiles {

  test {
    includeConfig 'conf/test.config'
  }
  docker {
    docker.enabled = true
    docker.fixOwnership = true
    singularity.enabled = false
    conda.enabled = false
  }
  singularity {
    singularity.enabled = true
    singularity.autoMounts = true
  }
  lehtio { 
    includeConfig "https://raw.githubusercontent.com/lehtiolab/static-resources/${params.external_config_version}/nf-configs/lehtio.config"
  }
  awsbatch {
    includeConfig 'conf/awsbatch.config'
    includeConfig 'conf/igenomes.config'
  }
  debug { process.beforeScript = 'echo $HOSTNAME' }
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')

timeline {
  enabled = true
  file = "${params.tracedir}/lehtiolab/execution_timeline_${trace_timestamp}.html"
}
report {
  enabled = true
  file = "${params.tracedir}/lehtiolab/execution_report_${trace_timestamp}.html"
}
trace {
  enabled = true
  overwrite = true
  // Dont use timestamp - we cannot get it in the onComplete handler,
  // where we somehow will have to parse this file
  file = "${params.outdir}/pipeline_info/execution_trace.txt"
  fields = 'task_id hash,native_id,name,tag,status,exit,submit,duration,realtime,%cpu,peak_rss,peak_vmem,rchar,wchar'
}
dag {
  enabled = true
  file = "${params.tracedir}/lehtiolab/execution_dag_${trace_timestamp}.svg"
}

manifest {
  name = 'lehtiolab/ddamsproteomics'
  author = 'Jorrit Boekel'
  homePage = 'https://github.com/lehtiolab/ddamsproteomics'
  description = 'Quantitative DDA MS proteomics pipeline'
  mainScript = 'main.nf'
  nextflowVersion = '>=24.04.4'
  version = '3.1'
  doi = '10.5281/zenodo.3548311'
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if(type == 'memory'){
    try {
      if(obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1) {
        return params.max_memory as nextflow.util.MemoryUnit
      } else {
        return obj
}
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'time'){
    try {
      if(obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'cpus'){
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}
